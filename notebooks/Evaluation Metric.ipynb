{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## importing packages\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from typing import Union\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## evaluation metric\n",
    "## from https://www.kaggle.com/c/m5-forecasting-accuracy/discussion/133834 and edited to get scores at all levels\n",
    "class WRMSSEEvaluator(object):\n",
    "\n",
    "    def __init__(self, train_df: pd.DataFrame, valid_df: pd.DataFrame, calendar: pd.DataFrame, prices: pd.DataFrame):\n",
    "        train_y = train_df.loc[:, train_df.columns.str.startswith('d_')]\n",
    "        train_target_columns = train_y.columns.tolist()\n",
    "        weight_columns = train_y.iloc[:, -28:].columns.tolist()\n",
    "\n",
    "        train_df['all_id'] = 0  # for lv1 aggregation\n",
    "\n",
    "        id_columns = train_df.loc[:, ~train_df.columns.str.startswith('d_')].columns.tolist()\n",
    "        valid_target_columns = valid_df.loc[:, valid_df.columns.str.startswith('d_')].columns.tolist()\n",
    "\n",
    "        if not all([c in valid_df.columns for c in id_columns]):\n",
    "            valid_df = pd.concat([train_df[id_columns], valid_df], axis=1, sort=False)\n",
    "\n",
    "        self.train_df = train_df\n",
    "        self.valid_df = valid_df\n",
    "        self.calendar = calendar\n",
    "        self.prices = prices\n",
    "\n",
    "        self.weight_columns = weight_columns\n",
    "        self.id_columns = id_columns\n",
    "        self.valid_target_columns = valid_target_columns\n",
    "\n",
    "        weight_df = self.get_weight_df()\n",
    "\n",
    "        self.group_ids = (\n",
    "            'all_id',\n",
    "            'cat_id',\n",
    "            'state_id',\n",
    "            'dept_id',\n",
    "            'store_id',\n",
    "            'item_id',\n",
    "            ['state_id', 'cat_id'],\n",
    "            ['state_id', 'dept_id'],\n",
    "            ['store_id', 'cat_id'],\n",
    "            ['store_id', 'dept_id'],\n",
    "            ['item_id', 'state_id'],\n",
    "            ['item_id', 'store_id']\n",
    "        )\n",
    "\n",
    "        for i, group_id in enumerate(tqdm(self.group_ids)):\n",
    "            train_y = train_df.groupby(group_id)[train_target_columns].sum()\n",
    "            scale = []\n",
    "            for _, row in train_y.iterrows():\n",
    "                series = row.values[np.argmax(row.values != 0):]\n",
    "                scale.append(((series[1:] - series[:-1]) ** 2).mean())\n",
    "            setattr(self, f'lv{i + 1}_scale', np.array(scale))\n",
    "            setattr(self, f'lv{i + 1}_train_df', train_y)\n",
    "            setattr(self, f'lv{i + 1}_valid_df', valid_df.groupby(group_id)[valid_target_columns].sum())\n",
    "\n",
    "            lv_weight = weight_df.groupby(group_id)[weight_columns].sum().sum(axis=1)\n",
    "            setattr(self, f'lv{i + 1}_weight', lv_weight / lv_weight.sum())\n",
    "\n",
    "    def get_weight_df(self) -> pd.DataFrame:\n",
    "        day_to_week = self.calendar.set_index('d')['wm_yr_wk'].to_dict()\n",
    "        weight_df = self.train_df[['item_id', 'store_id'] + self.weight_columns].set_index(['item_id', 'store_id'])\n",
    "        weight_df = weight_df.stack().reset_index().rename(columns={'level_2': 'd', 0: 'value'})\n",
    "        weight_df['wm_yr_wk'] = weight_df['d'].map(day_to_week)\n",
    "\n",
    "        weight_df = weight_df.merge(self.prices, how='left', on=['item_id', 'store_id', 'wm_yr_wk'])\n",
    "        weight_df['value'] = weight_df['value'] * weight_df['sell_price']\n",
    "        weight_df = weight_df.set_index(['item_id', 'store_id', 'd']).unstack(level=2)['value']\n",
    "        weight_df = weight_df.loc[zip(self.train_df.item_id, self.train_df.store_id), :].reset_index(drop=True)\n",
    "        weight_df = pd.concat([self.train_df[self.id_columns], weight_df], axis=1, sort=False)\n",
    "        return weight_df\n",
    "\n",
    "    def rmsse(self, valid_preds: pd.DataFrame, lv: int) -> pd.Series:\n",
    "        valid_y = getattr(self, f'lv{lv}_valid_df')\n",
    "        score = ((valid_y - valid_preds) ** 2).mean(axis=1)\n",
    "        scale = getattr(self, f'lv{lv}_scale')\n",
    "        return (score / scale).map(np.sqrt)\n",
    "\n",
    "    def score(self, valid_preds: Union[pd.DataFrame, np.ndarray]):\n",
    "        assert self.valid_df[self.valid_target_columns].shape == valid_preds.shape\n",
    "\n",
    "        if isinstance(valid_preds, np.ndarray):\n",
    "            valid_preds = pd.DataFrame(valid_preds, columns=self.valid_target_columns)\n",
    "\n",
    "        valid_preds = pd.concat([self.valid_df[self.id_columns], valid_preds], axis=1, sort=False)\n",
    "\n",
    "        group_ids = []\n",
    "        all_scores = []\n",
    "        for i, group_id in enumerate(self.group_ids):\n",
    "            lv_scores = self.rmsse(valid_preds.groupby(group_id)[self.valid_target_columns].sum(), i + 1)\n",
    "            weight = getattr(self, f'lv{i + 1}_weight')\n",
    "            lv_scores = pd.concat([weight, lv_scores], axis=1, sort=False).prod(axis=1)\n",
    "            group_ids.append(group_id)\n",
    "            all_scores.append(lv_scores.sum())\n",
    "\n",
    "        return group_ids, all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lb_rank(score):\n",
    "    \"\"\"\n",
    "    Get rank on public LB as of 2020-06-17 23:59:59\n",
    "    \"\"\"\n",
    "    df_lb = pd.read_csv(\"../data/m5-forecasting-accuracy-publicleaderboard.csv\")\n",
    "\n",
    "    return (df_lb.Score < score).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_calendar = pd.read_csv(\"../data/calendar.csv\")\n",
    "df_prices = pd.read_csv(\"../data/sell_prices.csv\")\n",
    "df_train_full = pd.read_csv(\"../data/sales_train_evaluation.csv\").astype({f'd_{i}': 'int32' for i in range(1, 1942)}) \n",
    "\n",
    "df_sample_submission = pd.read_csv(\"../data/sample_submission.csv\")\n",
    "df_sample_submission[\"order\"] = range(df_sample_submission.shape[0])\n",
    "\n",
    "df_train = df_train_full.iloc[:, :-28]\n",
    "df_valid = df_train_full.iloc[:, -28:]\n",
    "\n",
    "# evaluator = WRMSSEEvaluator(df_train, df_valid, df_calendar, df_prices)\n",
    "evaluator = joblib.load('WRMSSEEvaluator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for group all_id: 1.88936\n",
      "Score for group cat_id: 1.86489\n",
      "Score for group state_id: 1.8546\n",
      "Score for group dept_id: 1.90883\n",
      "Score for group store_id: 1.79608\n",
      "Score for group item_id: 1.28789\n",
      "Score for group ['state_id', 'cat_id']: 1.83237\n",
      "Score for group ['state_id', 'dept_id']: 1.84271\n",
      "Score for group ['store_id', 'cat_id']: 1.73791\n",
      "Score for group ['store_id', 'dept_id']: 1.71974\n",
      "Score for group ['item_id', 'state_id']: 1.2264\n",
      "Score for group ['item_id', 'store_id']: 1.16735\n",
      "\n",
      "Public LB Score: 1.67734\n",
      "Public LB Rank: 19154\n"
     ]
    }
   ],
   "source": [
    "preds_valid = pd.read_csv(\"../data/results/naive_submission.csv\")\n",
    "preds_valid = preds_valid[preds_valid.id.str.contains(\"validation\")]\n",
    "preds_valid = preds_valid.merge(df_sample_submission[[\"id\", \"order\"]], on = \"id\").sort_values(\"order\").drop([\"id\", \"order\"], axis = 1).reset_index(drop = True)\n",
    "preds_valid.rename(columns = {\n",
    "    \"F1\": \"d_1914\", \"F2\": \"d_1915\", \"F3\": \"d_1916\", \"F4\": \"d_1917\", \"F5\": \"d_1918\", \"F6\": \"d_1919\", \"F7\": \"d_1920\",\n",
    "    \"F8\": \"d_1921\", \"F9\": \"d_1922\", \"F10\": \"d_1923\", \"F11\": \"d_1924\", \"F12\": \"d_1925\", \"F13\": \"d_1926\", \"F14\": \"d_1927\",\n",
    "    \"F15\": \"d_1928\", \"F16\": \"d_1929\", \"F17\": \"d_1930\", \"F18\": \"d_1931\", \"F19\": \"d_1932\", \"F20\": \"d_1933\", \"F21\": \"d_1934\",\n",
    "    \"F22\": \"d_1935\", \"F23\": \"d_1936\", \"F24\": \"d_1937\", \"F25\": \"d_1938\", \"F26\": \"d_1939\", \"F27\": \"d_1940\", \"F28\": \"d_1941\"\n",
    "}, inplace = True)\n",
    "\n",
    "groups, scores = evaluator.score(preds_valid)\n",
    "\n",
    "score_public_lb = np.mean(scores)\n",
    "score_public_rank = get_lb_rank(score_public_lb)\n",
    "\n",
    "for i in range(len(groups)):\n",
    "    print(f\"Score for group {groups[i]}: {round(scores[i], 5)}\")\n",
    "\n",
    "print(f\"\\nPublic LB Score: {round(score_public_lb, 5)}\")\n",
    "print(f\"Public LB Rank: {score_public_rank}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for group all_id: 2.35575\n",
      "Score for group cat_id: 2.37345\n",
      "Score for group state_id: 2.17924\n",
      "Score for group dept_id: 2.36125\n",
      "Score for group store_id: 2.08827\n",
      "Score for group item_id: 1.0385\n",
      "Score for group ['state_id', 'cat_id']: 2.15274\n",
      "Score for group ['state_id', 'dept_id']: 2.11012\n",
      "Score for group ['store_id', 'cat_id']: 1.96389\n",
      "Score for group ['store_id', 'dept_id']: 1.85496\n",
      "Score for group ['item_id', 'state_id']: 0.91436\n",
      "Score for group ['item_id', 'store_id']: 0.84875\n",
      "\n",
      "Public LB Score: 1.85344\n",
      "Public LB Rank: 19358\n"
     ]
    }
   ],
   "source": [
    "preds_valid = pd.read_csv(\"../data/results/wavenet_exog_2206.csv\")\n",
    "preds_valid = preds_valid[preds_valid.id.str.contains(\"evaluation\")]\n",
    "preds_valid = preds_valid.merge(df_sample_submission[[\"id\", \"order\"]], on = \"id\").sort_values(\"order\").drop([\"id\", \"order\"], axis = 1).reset_index(drop = True)\n",
    "preds_valid.rename(columns = {\n",
    "    \"F1\": \"d_1914\", \"F2\": \"d_1915\", \"F3\": \"d_1916\", \"F4\": \"d_1917\", \"F5\": \"d_1918\", \"F6\": \"d_1919\", \"F7\": \"d_1920\",\n",
    "    \"F8\": \"d_1921\", \"F9\": \"d_1922\", \"F10\": \"d_1923\", \"F11\": \"d_1924\", \"F12\": \"d_1925\", \"F13\": \"d_1926\", \"F14\": \"d_1927\",\n",
    "    \"F15\": \"d_1928\", \"F16\": \"d_1929\", \"F17\": \"d_1930\", \"F18\": \"d_1931\", \"F19\": \"d_1932\", \"F20\": \"d_1933\", \"F21\": \"d_1934\",\n",
    "    \"F22\": \"d_1935\", \"F23\": \"d_1936\", \"F24\": \"d_1937\", \"F25\": \"d_1938\", \"F26\": \"d_1939\", \"F27\": \"d_1940\", \"F28\": \"d_1941\"\n",
    "}, inplace = True)\n",
    "\n",
    "groups, scores = evaluator.score(preds_valid)\n",
    "\n",
    "score_public_lb = np.mean(scores)\n",
    "score_public_rank = get_lb_rank(score_public_lb)\n",
    "\n",
    "for i in range(len(groups)):\n",
    "    print(f\"Score for group {groups[i]}: {round(scores[i], 5)}\")\n",
    "\n",
    "print(f\"\\nPublic LB Score: {round(score_public_lb, 5)}\")\n",
    "print(f\"Public LB Rank: {score_public_rank}\")\n",
    "# Public LB Score: 1.79532\n",
    "# Public LB Rank: 19330"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for group all_id: 2.05331\n",
      "Score for group cat_id: 2.08012\n",
      "Score for group state_id: 1.90374\n",
      "Score for group dept_id: 2.09028\n",
      "Score for group store_id: 1.83969\n",
      "Score for group item_id: 1.06288\n",
      "Score for group ['state_id', 'cat_id']: 1.8958\n",
      "Score for group ['state_id', 'dept_id']: 1.87992\n",
      "Score for group ['store_id', 'cat_id']: 1.75537\n",
      "Score for group ['store_id', 'dept_id']: 1.68268\n",
      "Score for group ['item_id', 'state_id']: 0.95473\n",
      "Score for group ['item_id', 'store_id']: 0.89992\n",
      "\n",
      "Public LB Score: 1.67487\n",
      "Public LB Rank: 19150\n"
     ]
    }
   ],
   "source": [
    "preds_valid = pd.read_csv(\"../data/results/wavenet_exog_2406.csv\")\n",
    "preds_valid = preds_valid[preds_valid.id.str.contains(\"evaluation\")]\n",
    "preds_valid = preds_valid.merge(df_sample_submission[[\"id\", \"order\"]], on = \"id\").sort_values(\"order\").drop([\"id\", \"order\"], axis = 1).reset_index(drop = True)\n",
    "preds_valid.rename(columns = {\n",
    "    \"F1\": \"d_1914\", \"F2\": \"d_1915\", \"F3\": \"d_1916\", \"F4\": \"d_1917\", \"F5\": \"d_1918\", \"F6\": \"d_1919\", \"F7\": \"d_1920\",\n",
    "    \"F8\": \"d_1921\", \"F9\": \"d_1922\", \"F10\": \"d_1923\", \"F11\": \"d_1924\", \"F12\": \"d_1925\", \"F13\": \"d_1926\", \"F14\": \"d_1927\",\n",
    "    \"F15\": \"d_1928\", \"F16\": \"d_1929\", \"F17\": \"d_1930\", \"F18\": \"d_1931\", \"F19\": \"d_1932\", \"F20\": \"d_1933\", \"F21\": \"d_1934\",\n",
    "    \"F22\": \"d_1935\", \"F23\": \"d_1936\", \"F24\": \"d_1937\", \"F25\": \"d_1938\", \"F26\": \"d_1939\", \"F27\": \"d_1940\", \"F28\": \"d_1941\"\n",
    "}, inplace = True)\n",
    "\n",
    "groups, scores = evaluator.score(preds_valid)\n",
    "\n",
    "score_public_lb = np.mean(scores)\n",
    "score_public_rank = get_lb_rank(score_public_lb)\n",
    "\n",
    "for i in range(len(groups)):\n",
    "    print(f\"Score for group {groups[i]}: {round(scores[i], 5)}\")\n",
    "\n",
    "print(f\"\\nPublic LB Score: {round(score_public_lb, 5)}\")\n",
    "print(f\"Public LB Rank: {score_public_rank}\")\n",
    "# Public LB Score: 1.79532\n",
    "# Public LB Rank: 19330"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for group all_id: 4.42741\n",
      "Score for group cat_id: 4.22194\n",
      "Score for group state_id: 4.07611\n",
      "Score for group dept_id: 4.14107\n",
      "Score for group store_id: 3.86068\n",
      "Score for group item_id: 2.30812\n",
      "Score for group ['state_id', 'cat_id']: 3.82603\n",
      "Score for group ['state_id', 'dept_id']: 3.70013\n",
      "Score for group ['store_id', 'cat_id']: 3.53413\n",
      "Score for group ['store_id', 'dept_id']: 3.2942\n",
      "Score for group ['item_id', 'state_id']: 2.06633\n",
      "Score for group ['item_id', 'store_id']: 1.88057\n",
      "\n",
      "Public LB Score: 3.44473\n",
      "Public LB Rank: 20062\n"
     ]
    }
   ],
   "source": [
    "preds_valid = pd.read_csv(\"../data/results/poisson_xgb_submission.csv\")\n",
    "preds_valid = preds_valid[preds_valid.id.str.contains(\"evaluation\")]\n",
    "preds_valid = preds_valid.merge(df_sample_submission[[\"id\", \"order\"]], on = \"id\").sort_values(\"order\").drop([\"id\", \"order\"], axis = 1).reset_index(drop = True)\n",
    "preds_valid.rename(columns = {\n",
    "    \"F1\": \"d_1914\", \"F2\": \"d_1915\", \"F3\": \"d_1916\", \"F4\": \"d_1917\", \"F5\": \"d_1918\", \"F6\": \"d_1919\", \"F7\": \"d_1920\",\n",
    "    \"F8\": \"d_1921\", \"F9\": \"d_1922\", \"F10\": \"d_1923\", \"F11\": \"d_1924\", \"F12\": \"d_1925\", \"F13\": \"d_1926\", \"F14\": \"d_1927\",\n",
    "    \"F15\": \"d_1928\", \"F16\": \"d_1929\", \"F17\": \"d_1930\", \"F18\": \"d_1931\", \"F19\": \"d_1932\", \"F20\": \"d_1933\", \"F21\": \"d_1934\",\n",
    "    \"F22\": \"d_1935\", \"F23\": \"d_1936\", \"F24\": \"d_1937\", \"F25\": \"d_1938\", \"F26\": \"d_1939\", \"F27\": \"d_1940\", \"F28\": \"d_1941\"\n",
    "}, inplace = True)\n",
    "\n",
    "groups, scores = evaluator.score(preds_valid)\n",
    "\n",
    "score_public_lb = np.mean(scores)\n",
    "score_public_rank = get_lb_rank(score_public_lb)\n",
    "\n",
    "for i in range(len(groups)):\n",
    "    print(f\"Score for group {groups[i]}: {round(scores[i], 5)}\")\n",
    "\n",
    "print(f\"\\nPublic LB Score: {round(score_public_lb, 5)}\")\n",
    "print(f\"Public LB Rank: {score_public_rank}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
